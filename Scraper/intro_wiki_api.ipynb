{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wikipedia Data Scraping: A Guide to Using the Wikipedia API\n",
        "\n",
        "In this Colab notebook, we aim to scrape data from Wikipedia using its Mediawiki API, through a python wrapper library [wikipedia](https://pypi.org/project/wikipedia/) . By referring to this demo notebook, students will have a basic idea of the wikipedia API and how to extract relevant data from the responses.\n",
        "\n",
        "Please note that you are not required to use this particular API for your Data Scraping task. Feel free to use any other libraries as long as it serves the purpose."
      ],
      "metadata": {
        "id": "M5KZdiNunJU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing and Importing Necessary Libraries\n"
      ],
      "metadata": {
        "id": "z-Fif5BAnD6H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqXRLgwu_H10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d4d745-00c8-4262-97f6-227df63d7ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=8f99af6c7425ccf66d6a0ddc3c1379b6623ba48a37143628941d9c72c63c8b9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia"
      ],
      "metadata": {
        "id": "Y7Eo989H_N3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Always run help command when you get stuck, for example if you don't know how to use the API read about it using the help()"
      ],
      "metadata": {
        "id": "2SSDVIyasPkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(wikipedia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRM-7gnEr-5Q",
        "outputId": "278724ee-6f9e-4069-829c-74c0425014af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package wikipedia:\n",
            "\n",
            "NAME\n",
            "    wikipedia\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    exceptions\n",
            "    util\n",
            "    wikipedia\n",
            "\n",
            "DATA\n",
            "    API_URL = 'http://en.wikipedia.org/w/api.php'\n",
            "    ODD_ERROR_MESSAGE = \"This shouldn't happen. Please report on GitHub: g...\n",
            "    RATE_LIMIT = False\n",
            "    RATE_LIMIT_LAST_CALL = None\n",
            "    RATE_LIMIT_MIN_WAIT = None\n",
            "    USER_AGENT = 'wikipedia (https://github.com/goldsmith/Wikipedia/)'\n",
            "    geosearch = <wikipedia.util.cache object>\n",
            "        Do a wikipedia geo search for `latitude` and `longitude`\n",
            "        using HTTP API described in http://www.mediawiki.org/wiki/Extension:GeoData\n",
            "        \n",
            "        Arguments:\n",
            "        \n",
            "        * latitude (float or decimal.Decimal)\n",
            "        * longitude (float or decimal.Decimal)\n",
            "        \n",
            "        Keyword arguments:\n",
            "        \n",
            "        * title - The title of an article to search for\n",
            "        * results - the maximum number of results returned\n",
            "        * radius - Search radius in meters. The value must be between 10 and 10000\n",
            "    \n",
            "    languages = <wikipedia.util.cache object>\n",
            "        List all the currently supported language prefixes (usually ISO language code).\n",
            "        \n",
            "        Can be inputted to `set_lang` to change the Mediawiki that `wikipedia` requests\n",
            "        results from.\n",
            "        \n",
            "        Returns: dict of <prefix>: <local_lang_name> pairs. To get just a list of prefixes,\n",
            "        use `wikipedia.languages().keys()`.\n",
            "    \n",
            "    search = <wikipedia.util.cache object>\n",
            "        Do a Wikipedia search for `query`.\n",
            "        \n",
            "        Keyword arguments:\n",
            "        \n",
            "        * results - the maxmimum number of results returned\n",
            "        * suggestion - if True, return results and suggestion (if any) in a tuple\n",
            "    \n",
            "    suggest = <wikipedia.util.cache object>\n",
            "        Get a Wikipedia search suggestion for `query`.\n",
            "        Returns a string or None if no suggestion was found.\n",
            "    \n",
            "    summary = <wikipedia.util.cache object>\n",
            "        Plain text summary of the page.\n",
            "        \n",
            "        .. note:: This is a convenience wrapper - auto_suggest and redirect are enabled by default\n",
            "        \n",
            "        Keyword arguments:\n",
            "        \n",
            "        * sentences - if set, return the first `sentences` sentences (can be no greater than 10).\n",
            "        * chars - if set, return only the first `chars` characters (actual text returned may be slightly longer).\n",
            "        * auto_suggest - let Wikipedia find a valid page title for the query\n",
            "        * redirect - allow redirection without raising RedirectError\n",
            "    \n",
            "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
            "\n",
            "VERSION\n",
            "    (1, 4, 0)\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.10/dist-packages/wikipedia/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Searching on specific keyword"
      ],
      "metadata": {
        "id": "SZ4FyNlBr6so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do a Wikipedia search for `query`. Default search returns 10 relevant pages (documents) for the query, you can play with the `results` parameter to change the number of retrieved results"
      ],
      "metadata": {
        "id": "kaXqdBiytKDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = wikipedia.search(\"Information Retrieval\", results=10)\n",
        "search_results"
      ],
      "metadata": {
        "id": "vEBVB09N_Q9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61705db0-3e6c-424c-82ef-eb4f3d128024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Information retrieval',\n",
              " 'Precision and recall',\n",
              " 'Evaluation measures (information retrieval)',\n",
              " 'Relevance (information retrieval)',\n",
              " 'Music information retrieval',\n",
              " 'Thesaurus (information retrieval)',\n",
              " 'Ranking (information retrieval)',\n",
              " 'Private information retrieval',\n",
              " 'Legal information retrieval',\n",
              " 'Cross-language information retrieval']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we dive deep to find out what is contained in each of the page, here we are retrieving the contents of the page titled as 'Information retrieval'. We are also setting the `auto_suggest` flag as `False` which prevents changing the text 'Information retrieval'."
      ],
      "metadata": {
        "id": "vi1uaU3OyNgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = wikipedia.page(search_results[0], auto_suggest=False)"
      ],
      "metadata": {
        "id": "aYZA4chX_VLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see a list of properties we can use on `content` object to retrieve the relevant informations"
      ],
      "metadata": {
        "id": "A68ibuoizkZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jSHZl0MzfMg",
        "outputId": "da3b5362-bca7-44bb-887c-d6895096cc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on WikipediaPage in module wikipedia.wikipedia object:\n",
            "\n",
            "class WikipediaPage(builtins.object)\n",
            " |  WikipediaPage(title=None, pageid=None, redirect=True, preload=False, original_title='')\n",
            " |  \n",
            " |  Contains data from a Wikipedia page.\n",
            " |  Uses property methods to filter data from the raw HTML.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __eq__(self, other)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __init__(self, title=None, pageid=None, redirect=True, preload=False, original_title='')\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  html(self)\n",
            " |      Get full page HTML.\n",
            " |      \n",
            " |      .. warning:: This can get pretty slow on long pages.\n",
            " |  \n",
            " |  section(self, section_title)\n",
            " |      Get the plain text content of a section from `self.sections`.\n",
            " |      Returns None if `section_title` isn't found, otherwise returns a whitespace stripped string.\n",
            " |      \n",
            " |      This is a convenience method that wraps self.content.\n",
            " |      \n",
            " |      .. warning:: Calling `section` on a section that has subheadings will NOT return\n",
            " |             the full text of all of the subsections. It only gets the text between\n",
            " |             `section_title` and the next subheading, which is often empty.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  categories\n",
            " |      List of categories of a page.\n",
            " |  \n",
            " |  content\n",
            " |      Plain text content of the page, excluding images, tables, and other data.\n",
            " |  \n",
            " |  coordinates\n",
            " |      Tuple of Decimals in the form of (lat, lon) or None\n",
            " |  \n",
            " |  images\n",
            " |      List of URLs of images on the page.\n",
            " |  \n",
            " |  links\n",
            " |      List of titles of Wikipedia page links on a page.\n",
            " |      \n",
            " |      .. note:: Only includes articles from namespace 0, meaning no Category, User talk, or other meta-Wikipedia pages.\n",
            " |  \n",
            " |  parent_id\n",
            " |      Revision ID of the parent version of the current revision of this\n",
            " |      page. See ``revision_id`` for more information.\n",
            " |  \n",
            " |  references\n",
            " |      List of URLs of external links on a page.\n",
            " |      May include external links within page that aren't technically cited anywhere.\n",
            " |  \n",
            " |  revision_id\n",
            " |      Revision ID of the page.\n",
            " |      \n",
            " |      The revision ID is a number that uniquely identifies the current\n",
            " |      version of the page. It can be used to create the permalink or for\n",
            " |      other direct API calls. See `Help:Page history\n",
            " |      <http://en.wikipedia.org/wiki/Wikipedia:Revision>`_ for more\n",
            " |      information.\n",
            " |  \n",
            " |  sections\n",
            " |      List of section titles from the table of contents on the page.\n",
            " |  \n",
            " |  summary\n",
            " |      Plain text summary of the page.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __hash__ = None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will specifically use the following:\n",
        "\n",
        "1. title\n",
        "2. revision_id\n",
        "3. summary\n",
        "4. URL"
      ],
      "metadata": {
        "id": "ktsj1sv2zx4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content.title"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hCNOLX6b59b1",
        "outputId": "b0a844ef-f430-4dc4-9242-0e8ffd9acfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Information retrieval'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.revision_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_g6jvlPCXjI",
        "outputId": "104f4f47-cb05-4dfd-c3c2-b4e1d03076b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1170129916"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "IK2Upwlp_o6z",
        "outputId": "8c421f7e-467d-4645-93aa-a7b79dbd1546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Information retrieval (IR) in computing and information science is the process of obtaining information system resources that are relevant to an information need from a collection of those resources.  Searches can be based on full-text or other content-based indexing. Information retrieval is the science of searching for information in a document, searching for documents themselves, and also searching for the metadata that describes data, and for databases of texts, images or sounds.\\nAutomated information retrieval systems are used to reduce what has been called information overload. An IR system is a software system that provides access to books, journals and other documents; it also stores and manages those documents. Web search engines are the most visible IR applications.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.url"
      ],
      "metadata": {
        "id": "m7lHeBQHECCf",
        "outputId": "7c83a990-fa1a-49e6-c1eb-5810bb6ba45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://en.wikipedia.org/wiki/Information_retrieval'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some other useful  properties.\n",
        "\n",
        "Suggestion: You may need this to retrieve 500 relevant pages (documents). You should traverse over the links to find the adequate number of unique documents."
      ],
      "metadata": {
        "id": "jpO4ZmfE00Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content.links"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqhq9iRb_2gj",
        "outputId": "a514418b-fcb4-470c-98e2-bb66508834a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1890 US Census',\n",
              " '3D retrieval',\n",
              " 'Adversarial information retrieval',\n",
              " 'Allen Kent',\n",
              " 'Alvin Weinberg',\n",
              " 'As We May Think',\n",
              " 'Association for Computing Machinery',\n",
              " 'Atlantic Monthly',\n",
              " 'Automatic summarization',\n",
              " \"Bayes' theorem\",\n",
              " 'Bibliometrics',\n",
              " 'Bill Maron',\n",
              " 'Binary Independence Model',\n",
              " 'C. J. van Rijsbergen',\n",
              " 'CERN',\n",
              " 'Calvin Mooers',\n",
              " 'Case Western Reserve University',\n",
              " 'Categorization',\n",
              " 'Censorship',\n",
              " 'Citation index',\n",
              " 'CiteSeerX (identifier)',\n",
              " 'Classification of the sciences (Peirce)',\n",
              " 'Co-occurrence',\n",
              " 'Collaborative information seeking',\n",
              " 'Communications of the ACM',\n",
              " 'Compound term processing',\n",
              " 'Computational linguistics',\n",
              " 'Computer data storage',\n",
              " 'Computer memory',\n",
              " 'Computing',\n",
              " 'Conference on Information and Knowledge Management',\n",
              " 'Controlled vocabulary',\n",
              " 'Cornelis J. van Rijsbergen',\n",
              " 'Cross-language information retrieval',\n",
              " 'Cultural studies',\n",
              " 'Cyril W. Cleverdon',\n",
              " 'Data mining',\n",
              " 'Data modeling',\n",
              " 'Data retrieval',\n",
              " 'Database',\n",
              " 'Desk Set',\n",
              " 'Desktop search',\n",
              " 'Digital libraries',\n",
              " 'Dimension reduction',\n",
              " 'Divergence-from-randomness model',\n",
              " 'Document classification',\n",
              " 'Doi (identifier)',\n",
              " 'Don Swanson',\n",
              " 'Donald B. Crouch',\n",
              " 'Emanuel Goldberg',\n",
              " 'Enterprise search',\n",
              " 'Eugene Garfield',\n",
              " 'European Conference on Information Retrieval',\n",
              " 'European Summer School in Information Retrieval',\n",
              " 'Evaluation measures (information retrieval)',\n",
              " 'Extended Boolean model',\n",
              " 'F. Wilfrid Lancaster',\n",
              " 'Federated search',\n",
              " 'Full-text search',\n",
              " 'Fuzzy retrieval',\n",
              " 'Generalized vector space model',\n",
              " 'Geographic information retrieval',\n",
              " 'Gerard Salton',\n",
              " 'Gerard Salton Award',\n",
              " 'Ground truth',\n",
              " 'Hans Peter Luhn',\n",
              " 'Hdl (identifier)',\n",
              " 'Herman Hollerith',\n",
              " 'Hierarchic clustering',\n",
              " 'Human–computer information retrieval',\n",
              " 'Hypertext',\n",
              " 'ISBN (identifier)',\n",
              " 'Ill-posed',\n",
              " 'Image retrieval',\n",
              " 'Independence (mathematical logic)',\n",
              " 'Informatics',\n",
              " 'Information Retrieval Facility',\n",
              " 'Information access',\n",
              " 'Information architecture',\n",
              " 'Information behavior',\n",
              " 'Information extraction',\n",
              " 'Information filtering',\n",
              " 'Information management',\n",
              " 'Information overload',\n",
              " 'Information retrieval applications',\n",
              " 'Information science',\n",
              " 'Information seeking',\n",
              " 'Information society',\n",
              " 'Information system',\n",
              " 'Information technology',\n",
              " 'Intellectual freedom',\n",
              " 'Intellectual property',\n",
              " 'International World Wide Web Conference',\n",
              " 'J. C. R. Licklider',\n",
              " 'JASIS',\n",
              " 'Jacquard loom',\n",
              " 'Joseph Marie Jacquard',\n",
              " 'Karen Spärck Jones',\n",
              " 'Karen Spärck Jones Award',\n",
              " 'Keypunch',\n",
              " 'Knowledge organization',\n",
              " 'Knowledge visualization',\n",
              " 'Language model',\n",
              " 'Latent Dirichlet allocation',\n",
              " 'Latent semantic analysis',\n",
              " 'Latent semantic indexing',\n",
              " 'Learning to rank',\n",
              " 'Legal information retrieval',\n",
              " 'Library and information science',\n",
              " 'MEDLARS',\n",
              " 'MIT',\n",
              " 'Melvin Earl Maron',\n",
              " 'Memory',\n",
              " 'Metadata',\n",
              " 'Mind maps',\n",
              " 'Mobile search',\n",
              " 'Multi-document summarization',\n",
              " 'Multimedia information retrieval',\n",
              " 'Music information retrieval',\n",
              " 'National Bureau of Standards',\n",
              " 'National Institute of Standards and Technology',\n",
              " 'Natural language user interface',\n",
              " 'Nearest centroid classifier',\n",
              " 'Nicholas J. Belkin',\n",
              " 'Nicholas Jardine',\n",
              " 'Ontology (computer science)',\n",
              " 'Orthogonality',\n",
              " 'Outline of information science',\n",
              " 'Pearl growing',\n",
              " 'Personal information management',\n",
              " 'Philosophy of information',\n",
              " 'Precision and recall',\n",
              " 'Preservation (library and archival science)',\n",
              " 'Privacy',\n",
              " 'Probabilistic relevance model',\n",
              " 'Probabilistic relevance model (BM25)',\n",
              " 'Punched cards',\n",
              " 'Quantum information science',\n",
              " 'Query understanding',\n",
              " 'Question answering',\n",
              " 'Ranking (information retrieval)',\n",
              " 'Recommender systems',\n",
              " 'Relevance (information retrieval)',\n",
              " 'Relevance feedback',\n",
              " 'Ricardo Baeza-Yates',\n",
              " 'Robert M. Hayes (information scientist)',\n",
              " 'Robert R. Korfhage',\n",
              " 'S2CID (identifier)',\n",
              " 'SMART Information Retrieval System',\n",
              " 'Scalability',\n",
              " 'Science',\n",
              " 'Science and technology studies',\n",
              " 'Search engine indexing',\n",
              " 'Search engines',\n",
              " 'Set (mathematics)',\n",
              " 'Site search',\n",
              " 'Social information seeking',\n",
              " 'Social search',\n",
              " 'Software engineering',\n",
              " 'Spam filtering',\n",
              " 'Special Interest Group on Information Retrieval',\n",
              " 'Standard Boolean model',\n",
              " 'Subject indexing',\n",
              " 'Tabulating machine',\n",
              " 'Taxonomy',\n",
              " 'Temporal information retrieval',\n",
              " 'Term Discrimination',\n",
              " 'Text Retrieval Conference',\n",
              " 'Text corpora',\n",
              " 'Tf–idf',\n",
              " 'Theodor Nelson',\n",
              " 'Tim Berners-Lee',\n",
              " 'Tony Kent Strix award',\n",
              " 'Topic-based vector space model',\n",
              " 'Uncertain inference',\n",
              " 'Univac',\n",
              " 'Vannevar Bush',\n",
              " 'Vector space model',\n",
              " 'Vertical search',\n",
              " 'Video retrieval',\n",
              " 'Wayback Machine',\n",
              " 'Web mining',\n",
              " 'Web search engine',\n",
              " 'World Wide Web',\n",
              " 'XML retrieval']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.url"
      ],
      "metadata": {
        "id": "eRAWpE05CRkN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d99be46b-c0ea-4ed6-d8e3-e55751300cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://en.wikipedia.org/wiki/Information_retrieval'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cua3piKz5Clh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}